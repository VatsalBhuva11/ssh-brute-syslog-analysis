# Important Commands for ELK Stack SSH Log Analysis

## Quick Start
docker compose up -d
./scripts/health_check.sh

## Health & Status Checks
./scripts/health_check.sh                    # Comprehensive health check
curl http://localhost:9200/_cluster/health?pretty  # ES cluster status
curl http://localhost:9200/authlogs/_count?pretty   # Document count
./scripts/monitor.sh                         # Real-time monitoring

## View Logs
./scripts/view_logs.sh                       # All services
./scripts/view_logs.sh logstash 200          # Logstash only (200 lines)
./scripts/view_logs.sh elasticsearch         # Elasticsearch only
./scripts/view_logs.sh kibana                # Kibana only
docker compose logs -f logstash               # Follow Logstash logs

## Query Elasticsearch
./scripts/query_elasticsearch.sh count       # Total document count
./scripts/query_elasticsearch.sh failed 20   # Show 20 failed attempts
./scripts/query_elasticsearch.sh top-ips 10  # Top 10 attacking IPs (uses src_ip.keyword)
./scripts/query_elasticsearch.sh top-users 10 # Top 10 targeted users
./scripts/query_elasticsearch.sh recent 5   # 5 most recent events
./scripts/query_elasticsearch.sh stats      # Overall statistics

# Note: For aggregations, use .keyword suffix (e.g., src_ip.keyword, status.keyword)

## Add Test Data
./gen_fake_ssh_attacks.sh 100                # Generate 100 fake attacks
echo 'Oct 31 12:55:01 arch sshd[3333]: Failed password for invalid user root from 10.0.0.7 port 22 ssh2' | sudo tee -a auth.log

## Reset & Maintenance
./scripts/reset_stack.sh                    # Reset everything (WARNING: deletes data)
docker compose down -v                       # Stop and remove volumes
docker compose restart logstash              # Restart Logstash only

## Kibana Access
http://localhost:5601
- Discover tab â†’ Create data view
- Index pattern: authlogs*
- Time field: @timestamp

## Elasticsearch API
curl http://localhost:9200/_cat/indices?           # List all indices
curl http://localhost:9200/_cat/shards/authlogs?  # Shard status
curl -X PUT 'http://localhost:9200/authlogs/_settings' -H 'Content-Type: application/json' -d '{"index":{"number_of_replicas":"0"}}'  # Fix yellow status

## Useful Queries
# Failed logins in last hour
curl -X POST "http://localhost:9200/authlogs/_search?pretty" -H 'Content-Type: application/json' -d '{"query":{"bool":{"must":[{"term":{"status.keyword":"Failed"}},{"range":{"@timestamp":{"gte":"now-1h"}}}]}}}'

# Top IPs with failed attempts
curl -X POST "http://localhost:9200/authlogs/_search?pretty" -H 'Content-Type: application/json' -d '{"size":0,"query":{"term":{"status.keyword":"Failed"}},"aggs":{"top_ips":{"terms":{"field":"src_ip.keyword","size":10}}}}'

## Create Forensic Evidence (E01 Format)
./scripts/create_evidence.sh                    # Create E01 evidence file (requires libewf)
./scripts/create_evidence.sh ./output case_001  # Specify output dir and case name
./scripts/extract_evidence.sh evidence.E01       # Extract evidence from E01 (handles padding)
./scripts/examine_evidence.sh evidence.E01       # Mount and examine E01 (interactive)
ewfverify evidence.E01                          # Basic E01 verification (may show false failures)

# Manual E01 operations (requires sudo)
./scripts/examine_evidence.sh evidence.E01      # Mount and examine E01 (recommended, interactive)

# Manual mounting and extraction:
sudo mkdir -p /tmp/ewf_mount                    # Create mount point
sudo ewfmount -f files -o nonempty evidence.E01 /tmp/ewf_mount  # Mount E01 (use -f files since created that way)
# Note: ewfmount creates ewf1 file (not evidence.tar.gz directly)
sudo cp /tmp/ewf_mount/ewf1 /tmp/evidence.tar.gz  # Copy ewf1 (it IS the tar.gz file)
tar -xzf /tmp/evidence.tar.gz                    # Extract evidence
sudo umount /tmp/ewf_mount                      # Unmount when done

# If extraction fails with "unexpected end of file", try different sizes:
for size in 6354 6451 6500; do sudo dd if=/tmp/ewf_mount/ewf1 bs=1 count=$size of=/tmp/test.tar.gz && tar -tzf /tmp/test.tar.gz && break; done
